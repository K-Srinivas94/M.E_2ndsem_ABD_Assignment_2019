1. Load batting.csv into a mysql in a database batdb and table batting

##MySQL Prompt
$ mysql -uroot -pcloudera

#create db:
create database battingdb;

#switch to database
use battingdb

#create table batting:
CREATE TABLE batting (
playerID varchar (20),
yearID int,
stint int,
teamID varchar (20),
lgID varchar (20),
G int,
G_batting int,
AB int,
R int,
H int,
2B int,
3B int,
HR int,
RBI int,
SB int,
CS int,
BB int,
SO int,
IBB int,
HBP int,
SH int,
SF int,
GIDP int,
G_old int
);

#load table from csv:
LOAD DATA INFILE '/home/cloudera/Desktop/BDA/DataFiles/Batting.csv' 
INTO TABLE batting 
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 LINES;

#######

2. Sqoop the details into hdfs.
#sqoop into HDFS
sqoop import --connect jdbc:mysql://localhost/batttingdb --username root --password cloudera --table batting --m 1 --target-dir /batting 

#######

3. Sqoop the details into hive.

##Hive prompt
$ hive

#create db  in hive
create database sqoop_db;

#sqoop into hive in command line
$ sqoop import --connect jdbc:mysql://localhost:3306/battingdb --username root --password cloudera --split-by yearID --table batting --target-dir /batting_hive_3 --fields-terminated-by "," --hive-import --create-hive-table --hive-table sqoop_db.batting;

#######

4. Implement a PIG script to 

##load data to the pig prompt -->> pig
batting_list = LOAD '/home/cloudera/Batting.csv' USING PigStorage(',') as (playerID:chararray,
yearID:int,
stint:int,
teamID:chararray,
lgID:chararray,
G:int,
G_batting:int,
AB:int,
R:int,
H:int,
B2:int,
B3:int,
HR:int,
RBI:int,
SB:int,
CS:int,
BB:int,
SO:int,
IBB:int,
HBP:int,
SH:int,
SF:int,
GIDP:int,
G_old:int);

----
a) Find the total count of participation of G 112
----

count_g = FILTER batting_list BY G == 112;
group_count_g  = GROUP count_g All;
total_count = foreach group_count_g Generate COUNT(count_g.G);
dump total_count;
### --->> 209

----
b) Find the player details with "david" 
----

david  = Filter batting_list by(playerID MATCHES 'david.*');
dump david;
Store david into 'home/cloudera/Desktop/assign_pigresults';

----
c) Find the average count of "NL"
----

NL_filter = Filter batting_list by lgID =='NL';
NL_Group = Group NL_filter All;
NL_avg = foreach NL_Group Generate AVG(NL_filter.G_batting);
DUMP NL_avg;
### --->> 51.957273064709035

----
d) Find the count of teams
----

team_count = GROUP batting_list by teamID;
team_group = GROUP team_count All;
result_count = Foreach team_group Generate COUNT(team_count);
dump result_count;
### --->> 149

#######

5. Implement a Hive script to
----

a) Find the total count of player details with "david"
use sqoop_db;
select count(*) from batting where playerID like "david%";

-----

b) Create a patition on the TEAMID
c) Create 3 buckets on the partition.

create external table batting_part(playerID string,
yearID int,
stint int,
lgID string,
G int,
G_batting int,
AB int,
R int,
H int,
B2 int,
B3 int,
HR int,
RBI int,
SB int,
CS int,
BB int,
SO int,
IBB int,
HBP int,
SH int,
SF int,
GIDP int,
G_old int)
partitioned by (teamID string)
clustered by (lgID) INTO 3 buckets
row format delimited
fields terminated by ','
stored as textfile;

create external table batting_hive(playerID string,
yearID int,
stint int,
teamID string,
lgID string,
G int,
G_batting int,
AB int,
R int,
H int,
B2 int,
B3 int,
HR int,
RBI int,
SB int,
CS int,
BB int,
SO int,
IBB int,
HBP int,
SH int,
SF int,
GIDP int,
G_old int)
row format delimited
fields terminated by ','
stored as textfile;

LOAD DATA LOCAL INPATH '/home/cloudera/Desktop/Batting.csv' OVERWRITE INTO TABLE batting_hive;

set hive.exec.dynamic.partition.mode=nonstrict;
set hive.exec.dynamic.partition=true;
set hive.enforce.bucketing=true;
set hive.exec.dynamic.partition.pernode=20000;

from batting_hive bat INSERT OVERWRITE TABLE batting_part PARTITION(teamID)
select bat.playerID,bat.yearID,
bat.stint ,bat.teamID,bat.lgID ,
bat.G ,bat.G_batting ,
bat.AB ,bat.R ,bat.H ,
bat.B2 ,bat.B3 ,
bat.HR ,bat.RBI ,
bat.SB ,bat.CS ,bat.BB ,
bat.SO ,bat.IBB, bat.HBP,
bat.SH ,bat.SF,bat.GIDP,
bat.G_old 
DISTRIBUTE BY teamID;

----

d) Extract the details on player "aaronha01"
select * from batting_part where playerID='aaronha01';

----

----
e) Find the count of teams
select count(distinct(teamID)) from batting_hive;

-----

########
9. Using hive,partition by year. Then, find the year wise count of participants, 
find the total votes got by the players.

create table halloffame(hofID STRING, yearid INT, votedBy STRING, ballots INT, needed INT, votes INT,inducted STRING, category STRING, needed_note STRING) row format delimited fields terminated by ',' stored as textfile;

LOAD DATA LOCAL INPATH '/home/cloudera/Lab/DataFiles/HallOfFame.csv' into table halloffame;

set hive.exec.dynamic.partition.mode=nonstrict;
set hive.exec.dynamic.partition=true;
set hive.enforce.bucketing=true;

create table halloffame_part_hof(hofID STRING, votedBy STRING, ballots INT, needed INT, votes INT,inducted STRING, category STRING, needed_note STRING) partitioned by(yearid INT) row format delimited fields terminated by ',' lines terminated by '\n';

from halloffame hof INSERT OVERWRITE TABLE halloffame_part_hof PARTITION(yearid) select hof.hofID, hof.votedBy, hof.ballots, hof.needed, hof.votes, hof.inducted, hof.category, hof.needed_note, hof.yearid  DISTRIBUTE BY yearid;

select yearid, count(hofid) from halloffame_part_hof group by yearid;

select hofid, sum(votes) from halloffame_part_hof group by hofid;

#######

